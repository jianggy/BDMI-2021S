# WW6课程小结

2021.3.30

keras

### 自动微分(autodiff)

#### 求导运算

+ 数值微分：根据导数定义计算，结果不准确

+ 符号微分Symbolic：复杂程度指数增加
+ 自动微分Automatic Differentiation：应用数学的研究
  + 前向模式：二元数方法，
  + 反向模式：（常见）反向计算图方法，计算了**输出对所有输入**的微分值

#### 反向传播

传统：按前向传播计算并缓存，再反向传播求微分

#### 自动微分

反向计算图，不需要缓存所有图

**架构算法**：图的算法

#### 静态和动态的反向计算图

静态：define-and-run，架构模型时即建好了架构图

动态：define-by-run，训练时再架构

### Python类和继承

+ 类Class
  + 属性 Attribute
  + 方法 Method

+ 对象Object ：类的一个实例
  + 实例化 Instance
  + 参数Parameter

#### python中的类

类、构造函数、方法的第一个参数必须是self

#### 类的继承

super() 方法，调用父类方法

```python
c=Child()
super(Child,c).myMethod() #到child上一级
```

call()方法

### TensorFlow中的模块和层

模块（定义，保存，恢复）

#### 层

dense

#### ![1617089052784屏幕截图 2021-03-30 143931](C:\Users\XUzy\Desktop\1617089052784屏幕截图 2021-03-30 143931.png)

#### 从层到模型

#### 模型存储及恢复

```python
tf.train.Checkpoint()
checkpoint.write(chkp,path)
```

存储路径

>  python装饰器
>
> @tf.function

恢复模型 tf.saved_model

#### tensorboard可视化工具

### Tensorf计算图



Graph 图

由节点和线组成，计算图本质是数据流图

```python
tf.function #类似python中的函数
funGraph=tf.function(myFun)

funGraph(x,w,b).nump()
```

tf.function()上可以使用不同类型和形状的数据

#### Keras

使用Keras模型以记录checkpoint