### Memo - Week 5

#### Tensorflow

#### 1. 张量

* 概念

* 创建

  * tf.constant
  * Tips：末尾几个“[ ]”即几个维度

* 运算

  * 转换为numpy：np.array(张量名) / 张量名.numpy()
  * tf.add 对应元素相加
  * tf.multiply 对应元素相乘
  * tf.matmul 矩阵乘法
  * tf.reduce_max 寻找元素最大值
  * tf.argmax 求最大值的索引
  * tf.nn.softmax 对元素进行归一化处理

* Dtypes

  * 数据类型转换：tf.cast(tensor, dtype, name=None)
  * tf.reshape(tensor,shape,name=None)
    * shape表示：eg. 三维转二维，shape为[x, y] or [z,-1]

* 广播

  * 组合运算时，扩展小张量以适应大张量

* 索引

  * 单轴
    * start:stop:step
  * 多轴
    * [row, column]

* 特殊张量

  * 不规则张量

    * tf.ragged.constant(张量)创建
    * shape存在none

  * 字符串张量

    * dtype=string

    * 分割：tf.strings.split

    * 转换为字节：tf.strings.bytes_split()

      转换为数值：tf.io.decode_raw()

  * 稀疏张量

    * tf.sparse.SparseTensor(indices, values, dense_shape)

      Tf.sparse.to_dense()

#### 2. 变量

* 与张量相似，可存储模型参数
* 创建
  * tf.Variable()
  * 数据类型不限
* 结构
  * .shape，.dtype，.numpy
* 特性
  * 变量无法改变形状，reshape会新建一个张量
  * 变量的值可以通过assign函数更改
* 运算
  * tf.convert_to_tensor
  * tf.argmax查询最大值对应索引号
  * 从现有变量创建新的变量 .assign()
  * 加减 .assign_add() / .assign_sib()
* trainable = False 关闭梯度

#### 3. 自动微分🌟

* 梯度带
  * tf.GradientTape
  * <img src="/Users/zhengyufei/Library/Application Support/typora-user-images/image-20210330101738933.png" alt="image-20210330101738933" style="zoom: 67%;" />
  * <img src="/Users/zhengyufei/Library/Application Support/typora-user-images/image-20210330101830207.png" alt="image-20210330101830207" style="zoom:50%;" />
  * 通过创建一个持久的梯度带，可以计算同个函数的多个导数。可多次调用 'gradient()。
    * tf.GradientTape(persistent=True)
* 记录控制流
* 高阶导数

#### 问题

对自动微分部分代码的理解和使用掌握不足