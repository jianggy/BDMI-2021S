# study memo day 5

#### 2017080040 松本博晓 16



## TensorFlow

```
import numpy as np
def softmax(x):
    return np.exp(x)/np.sum(np.exp(x))
x = np.array([22,35,86])
w1 = np.random.normal(size=(3,3))
w2 = np.random.normal(size=(3,2))

N = np.dot(x, w1)
Y= softmax(np.dot(N,w2))
print(N)
```



### 2维张量的创建

```
import numpy as np
import tensorflow as tf

rank_2_tensor = tf.constant([[1,2],
                            [3,4],
                            [5,6]],dtype = tf. float16)
rank_2_tensor
```

```
<tf.Tensor: shape=(3, 2), dtype=float16, numpy=
array([[1., 2.],
       [3., 4.],
       [5., 6.]], dtype=float16)
```

### 3维张量的创建

```
import numpy as np
import tensorflow as tf

rank_3_tensor = tf.constant([
    [[1,2,3],[4,5,6]],
    [[1,2,3],[4,5,6]],
    [[1,2,3],[4,5,6]],])
rank_3_tensor
```

```
<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=
array([[[1, 2, 3],
        [4, 5, 6]],

       [[1, 2, 3],
        [4, 5, 6]],

       [[1, 2, 3],
        [4, 5, 6]]])
```

### 3维张量转换为数组

```
np.array (rank_3_tensor)
```

### 运算

1. tf.add 对应元素相加
2. tf.multiply 对应元素相乘
3. tf.matmul 矩阵相乘
4. tf.reduce_max 寻找最大值
5. tf.argmax 求最大值的索引
6. tf.nn.softmax 对元素进行归一化处理



### 求导 

```
x = tf. constant([1.0])
with tf.GradientTape() as t:
    t.watch(x)
    y=x*x+tf.exp(x)
dy_dx = t.gradient(y,x)
print(dy_dx)
```



## 其他

随机矩阵生产

例子 2x3

```
c = np.random.normal(size=(2,3))
```

