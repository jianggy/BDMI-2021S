# Week 3课程小结

## 学习内容

+ **numpy**
  + 矩阵的创建及运算
+ **深度学习1**
  + 人工神经元-----带权重的函数
    + 第一步：将一组输入做线性加权叠加
    + 第二步：将第一步的结果做非线性变换---激活函数
  + 常见激活函数
    + sigmoid函数/s形函数/逻辑斯提函数
      - 𝑠𝑖𝑔𝑚𝑜𝑖𝑑(𝑥)=1/(1+𝑒𝑥𝑝(−𝑥))sigmoid(x)=1/(1+exp(−x))
    + tanh函数/th函数
      - 𝑡𝑎𝑛ℎ(𝑥)=(𝑒𝑥𝑝(𝑥)−𝑒𝑥𝑝(−𝑥))/(𝑒𝑥𝑝(𝑥)+𝑒𝑥𝑝(−𝑥))tanh(x)=(exp(x)−exp(−x))/(exp(x)+exp(−x))
    + relu函数/整流线性单元
      - 𝑅𝑒𝐿𝑢(𝑥)=𝑚𝑎𝑥(𝑥,0)
  + 逻辑斯提回归单元、整流线性单元的实现
  + 单个人工神经元-模拟布尔运算
    + 利用 sigmoid函数在x>10基本为1,x<-10基本为0
  + 二层网络解决 异或 问题
+ **深度学习2**
  + 多层神经网络（深度学习）解决的两类问题
    + 分类（若人工调节参数，单神经元也可以实现）
    + 预测
  + **权重自动确定/神经网络的训练**
    + 确定损失函数
      + 分类任务--交叉熵
      + 回归任务--均方误差
    + 权重初始化
    + 反向传播
    + 权重修正

## 学习心得

+ numpy 在矩阵运算方面十分便捷，比如人工神经元中做线性加权叠加时，利用dot函数很方便
+ 构建神经网络时如何确定权重是一个有挑战的步骤，需要经验积累