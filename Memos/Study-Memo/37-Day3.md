### Week 3 summary

2021.3.9

***

- Numpy;数学工具包

  - 数组创建与类型定义

    ```python
    c=np.array([],[],[])
    ```

  - 算数运算

    ```python
    a+4
    a*2
    a+b
    a*b/对应位置相乘
    ```

  - 常用方法

    ```python
    np.sin()
    np.sqrt()
    np.arange().reshape(3,3)
    np.ones((3,3))
    np.square()
    np.max()
    np.maximum()
    ```

  - 矩阵乘积

    the operation is not element-wise

    ```python
    np.dot(a,b)
    ```

  - 数组变形

    ```python
    a=np.random.random(12)/产生
    A=a.reshape(3,4)/变形
    a.shape=(3,4)
    a=a.revel()/降至1维
    a.shape=(12)
    a.transpose()/转置
    ```

  - 其他语句

    ```python
    np.zeros
    np.identity
    np.arange
    ...
    array.shape/get sahpe of numpy array
    type()/check data type of array 
    ```

- 人工神经元

  - 激活函数

    ```python
    %matplotlib inline
    import matplotlib.pyplot as plt
    import numpy as np
    
    relu = lambda x:np.maximum(x,0)#please notice the difference from np.max
    sigmoid = lambda x:1/(1+np.exp(-x))
    tanh = lambda x:(np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))
    
    x=np.linspace(-10,10,200)
    plt.plot(x,relu(x),color='red')
    plt.plot(x,sigmoid(x),color='blue',lw=3)
    plt.plot(x,tanh(x),color='green')
    ```

  - relu单元

    ```python
    import matplotlib.pyplot as plt
    import numpy as np
    
    relu = lambda x:np.maximum(x,0)
    x=np.array([1,0,1])
    y=np.array([-0.21,0.3,0.7])
    relu(np.dot(np.transpose(x),y))#这里不需要转置
    ```

  - 描述AND\OR\NOT\NAND运算

    ```python
    w=[20,20]
    AND = lambda x:sigmoid(np.dot(w,x)-30)
    OR = lambda x:sigmoid(np.dot(w,x)-10)
    NOT = lambda x:sigmoid(-20x+10)
    #NAND(x,y)=(not x)or(not y)
    w_=[-20,-20]
    NAND = lambda x:sigmoid(np.dot(w,x)+30)
    ```

  - 异或问题比较困难

    多层网络实现,单个无法解决

- 多层神经网络

  - 多层神经网络（又称深度学习）

    - 神经网络方法：机器学习监督学习方法；

    - 应用

      - 分类任务（Classification）
        - 单个神经元，二元分类
      - 回归任务（Regression）

    - softmax实现

      ```python
      import matplotlib.pyplot as plt
      import numpy as np
      def softmax(x):
          x_exp = [np.exp(i) for i in x]
          sum_x_exp = sum(x_exp)
          return [round(i/sum_x_exp,3) for i in x_exp]
      a=np.array(range(10))
      softmax(a)
      ```

    - logit分对数sigmoid的反函

  - 自动化权重更新

    - 损失函数（需要最小化的目标

      - 回归问题用均方误差MSE

        ```pyhton
        def MSE(x,y):
            m = 0
            for i in x:
                m += pow((i-y),2)
            a = x.shape#获取矩阵的行数
            m = m / a[0]
            return m
        
        print(MSE(...,80))
        ```

        

      - 分类问题用交叉熵CE（负对数似然损失函数）（写一个简单的函数就行了）

    - 权重初始化

    - 反向传播

    - 权重修正

#### 问题总结

***

1. 在宿舍里有点注意力不集中

2. 矩阵乘法不会，已自学

3. 写总结的时候才发现其实内容还挺简单的；rush！

   :kissing_heart: