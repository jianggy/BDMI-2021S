### Memo for Week 3-李蔚然

#### What I've learned?

- **numpy**
  	专门对矩阵的操作，和matlab中的一些功能很像，感觉能想到的矩阵操作相关的功能差不多都具备了。

- **深度学习1**：人工神经元相关

  - 人工神经元：带权重的函数
    - 激活函数
      - sigmoid函数：$sigmoid(x)=\frac{1}{1+e^{-x}}$
      - tanh函数：$tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}$
      - ReLU函数：$ReLU(x)=max(x,0)$
    - ReLU单元（整流线性单元）、逻辑斯提回归单元(Logistic Regression Unit,通常采用Sigmoid函数或逻辑斯提函数)
  - 单个人工神经元的能力：布尔运算
    - AND运算、OR运算、NOT运算、NAND运算
  - 多个神经元的能力：可以解决更复杂的问题，比如XOR运算

- **深度学习2**：神经网络相关

  - 神经网络方法：机器学习的监督学习方法(supervised learning)

  - 多层神经网络：如何实现网络权重的自动化更新？

    - 确定损失函数

      - 对于回归任务，可用**均方误差MSE**公式

      - 对于分类任务，可用**交叉熵CE**公式

        ​	交叉熵是负对数似然损失函数，$$H_{y'}(y)=-\sum_{i}y_i'log(y_i)$$，优化目标是使交叉熵尽量小

    - 权重初始化

    - 反向传播

    - 权重修正

#### Overall feeling

​	在使用numpy的过程中，体会到了numpy和matlab功能的重合和相似，之前美国对哈工大禁用matlab时，就有人说其实用Python也能实现matlab的大部分功能（除simulink外），感觉的确如此如此，numpy库的矩阵运算功能很强大。
​	同时这也是我第一次接触机器学习、神经网络相关的东西，之前觉得可能很深奥，不是我能轻易学会的东西。不过一节课下来，老师从最基本的人工神经元讲起，也使我渐渐理解庞大复杂的神经网络究竟是如何构成的。同时，整个神经网络的构成方式也与我之前的的一些猜想基本吻合。所谓“智能”，我的理解就是是一个“类人”的行为，而这归根到底也是由一个个基本的逻辑布尔运算构成的，但是还没有想通的是该如何管理由基本逻辑运算构成的庞大的系统（其实专业课的数电也是需要处理这种问题，但还没有学到）。



