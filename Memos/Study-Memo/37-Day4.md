### Week 4 summary

2021.3.16

***

- Pandas
  - numpy数组构建的一个数据分析包，更能处理大型数据集
  - 数据结构
    - 一维数据结构series
    
    - 二维数据结构dataframe
      
      - 创建方法，字典(非常常用)
      
      ```python
      pd.DataFrame({f"col{i}":np.random.randn(3) for i in range(4)})
      #create a table with 4 columns and 3 lines
      ```
      
    - 三维数据结构panal
  - 数据写入写出
    - 读写excel、csv
    
    - ```python
      pn.read_excel('xxx.xlsx')
      pn.to_csv(r'C:\xxx\xxx\xxx\xxx.csv')
      ```
- Deep Learning 2
  - 分类问题：希望归一化为概率向量所以用softmax（）此函数在对数似然的运算中具有得天独厚的优越性

  - 损失函数     **J**  （ 见上节）

  - 反向传播（核心过程）

    铺垫：

    **J**是权重值的函数，求极小值（其实是函数的函数；变分）

    梯度向量的方向是向上的

    将求权重值的grad的过程分解为每一次简单函数的求导并利用来链式法则求出结果

    （$J=f'-f$）第一部J是f的函数并求导（$-1$）

    - 梯度下降原理

    - 合理性：

      分类结果抽象为概率函数；概率函数设为各项人认为可能原因权重的线性函数并利用softmax归一化；利用数据学习得出最优化的权重值；最优化过程类似牛顿法数值计算不断逼近

  - 权重更新

    - $w+=η*gradf$
    - 学习步长$η=0.01$；太小-->慢；太大-->振动

  - 训练概念

    - 批次batch
    - 迷你批次 mini-batch
    - 迭代iteration
    - 时代epoch
    - 参数固化frozen

  - python张量积算

  - tensorflow数值计算
- 二元分类（logistic回归）
  
  - 模型实践
  
  - 全代码演示
  
    - 漂亮！
  
      [image-20210318214543312](C:\Users\phoetex\AppData\Roaming\Typora\typora-user-images\image-20210318214543312.png)
- Tensorflow2 playground
  - test loss> training loss 过拟合问题
  - 为什么需要用深度学习：深度比较高的对于下一级可以调用，效率更高；宽度大的效率不够
  - 体验如何设置神经元个数可以最快得出最准确的结果；宽度和深度都有讲究

#### 问题总结

***

1. 之前一直pip install缓慢可能是pip的安装有问题

2. 对于似然法的内涵想要了解一下具体的数学过程：似然即最符合样本的’概率‘；。。。

   :kissing_heart: