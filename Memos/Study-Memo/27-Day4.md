# 第四周学习小结

2021.3.16 线下学习

 :happy:

## 1. Python Pandas

+ 定义：Pandas是基于numpy数组构建的一个数据分析包，pandas的优势是更方便地操作大型数据集，很多指令是通用的。
+ 数据结构
  + 一维——Series和ndarray的不同之处：Series的操作默认是使用index的值进行对齐的，而不是相对位置。

  + 二维——是表格型的数据类型，既有行索引，也有列索引。构建方式：字典/二维数组

    + 通过二维数组构建Data

      ```python
      dates = pd.date_range('20200101',periods=6)
      df=pd.DataFrame(np.random.randn6,4),index=dates,columns=list('ABCD')
      ```

    + 通过Series字典构建Data

      ```python
      d={'one':pd.Series([1.,2.,3.],index=['a','b','c']),'two':pd.Series([1.,2.,3.,4.],index=['a','b','c','d'])}
      df=pd.DataFrame(d)
      ```

  + 三维
+ I/O操作
  + 读写CSV文件
  
  + 读写Excel文件
  
  + ```python
    xx.to_csv('xxx.csv')
    xx.to_excel('xxx.xlsx')
    pd.read_csv('xxx.csv') 
    pd.read_excel('xxx.xlsx')  
    ```

## 2.  Deep Learning II

+ 梯度
  + 概念：导数的方向
  + 反向传播：损失函数J是权重值的函数，要计算损失函数对权重的梯度，应用链式求导法则
  + 最优化算法——梯度下降法（最速下降法）
+ 神经网络的训练过程:arrow_right:损失函数的最小化:arrow_right:梯度
+ 分解算子的计算过程
+ 权重更新——随机梯度下降法
  + 随机梯度下降法（SGD）是最常用的权重调节方法，通过权重的调整，最小化损失函数。
  + 随机梯度下降法的核心是一个“随机样本”
  + 步骤：
    1. 随机初始化每个神经元输入权重和偏差
    2. 选取一个随机样本
    3. 根据网络的输出结果，从最后一层开始，逐层计算每层权重的偏导数
    4. 逐层调整每层的权重，产生新的权重值
    5. 返回到步骤2，继续随机选取下一个样本
+ 神经网络的实际训练过程
  + 将样本数据分批输入模型，进行“分批训练”，最简单的批量选择是使用整个数据集，又称批量训练
  + 整个训练集称为一个批次，切分成多个大小相同的子集，每个子集称为一个迷你批次，又称为小批量
  + 小批量训练是批量训练和随机梯度下降法的一个折中
  + 一次迭代&一个时代的概念
+ 用张量表示神经网络
  + 张量的实质是N维数组
  + 一种数据思维的方式

## 3. 二元分类

+ 神经网络的应用
+ 经验调参法:arrow_right:自动调参法
+ 自动化训练流程
  1. 获取训练数据
  2. 搭建模型
  3. 定义损失函数
  4. 运行训练数据，从目标值计算损失
  5. 计算损失的梯度，并使用优化器来调整变量以适应数据
  6. 结果评估
+ [代码范例](https://github.com/saturn-lab/BDMI-2021S/blob/main/Computing/logistic_regression/logistic_regression_scratch.ipynb)

## 4.TensorFlow2 Playground

+ 测试的loss大于训练的loss的原因是：过拟合
+ 学习率过大会引起震荡，学习率太小则会收敛太慢



***存在的问题***

深度学习的第二部分内容在理解上有难度，感觉有些抽象。

***

感谢老师和助教们的耐心讲解和指导！:heartpulse: