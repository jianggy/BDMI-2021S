### Memo - Week3

1. **numpy**

   * 数据类型
     * np.array
   * 算数运算、函数运算
   * 矩阵运算
     * 点乘dot()函数
   * 增减运算
   * 数组变形
     * reshape()、ravel()、transpose()

2. **人工神经元**

   * 激活函数
     * sigmoid、tanh、ReLU
   * ReLU单元
     * 权重/加权叠加 ➡️ 激活函数
     * <img src="/Users/zhengyufei/Library/Application Support/typora-user-images/image-20210316105800598.png" alt="image-20210316105800598" style="zoom:50%;" />
   * 逻辑斯提回归单元
     * <img src="/Users/zhengyufei/Library/Application Support/typora-user-images/image-20210316105738438.png" alt="image-20210316105738438" style="zoom:50%;" />
     * 激活函数：sigmoid / 逻辑斯提
   * 布尔运算
     * 与运算（AND）、或运算（OR）、非运算（NOT）
     * 与非（NAND）、异或（XOR）

3. **深度学习**

   * 多层神经网络概论
     * 监督学习
     * 分类与预测
   * 单个神经元进行二元分类
     * 权重：正负（正负相关）、大小（越大越重要）
   * 多层神经网络
     * 两层神经网络解决XOR问题
     * 网络层：输入层、隐藏层、输出层
     * 输出层运用softmax () 归一化为概率向量
       * 所有分量之和为1
       * <img src="/Users/zhengyufei/Library/Application Support/typora-user-images/image-20210316111716918.png" alt="image-20210316111716918" style="zoom:50%;" />

   * logit分对数模型
     * 把区间(0,1)内的数值，变换到区间(-∞,﹢∞)
     * 与sigmoid函数互为反函数
   * 多层网络权重的确定
     * 确定损失函数 ➡️ 权重初始化 ➡️ 反向传播 ➡️ 权重修正
     * 损失函数
       * 回归任务：均方误差MSE
         * vs. 均方差（i.e.标准差）
       * 分类任务：交叉熵 / 负对数似然损失函数
         * <img src="/Users/zhengyufei/Library/Application Support/typora-user-images/image-20210316112213916.png" alt="image-20210316112213916" style="zoom:50%;" />