## week3 memo

### Part1- Numpy

```
import numpy as np
a=np.array(···)  #创建数组，内容可包括列表或元组  
a=np.arange(4)   #定义范围(开始，停止，步长)
```

- operators 仅作用于对应位置的元素

- 矩阵代数相乘使用np.dot(A,B)

- np.reshape()  转换数组的形状，返回新的数据对象

- np.ravel() 将多维数组转换为一维数组

  

### Part2-深度学习1

###### 人工神经元（带权重的函数）

1. 激活函数

   $$ sigmoid(x)=\frac{1}{1+e^{-x}} $$

   $$ tanh(x)=\frac{e^x - e^{-x}}{e^x + e^{-x}} $$

   ReLU(x)=max(x,0)

2. 逻辑斯提回归单元

   将一组输入的线性加权叠加后，经过一个非线性函数（激活函数）进行输出

3. 整流线性单元ReLU

###### 单个人工神经元的能力-模拟布尔运算

- 与，非，或，与非

###### 多个人工神经元的能力-XOR问题

$$ A⊕B= AB' + BA'= (A+B)(AB)'=(A'+B)(A+B')  $$



### Part3-深度学习2：多层神经网络

机器学习的监督学习的方法

**用来做什么？**通过对数据集的学习 ：

- 分类任务：对新数值进行集合分类——分类方法

  - 用经验调参法找到合适的权重
  - 网络层数越多，表达能力越强，但权重数量越多
  - 自动化的权重确定方法：用交叉熵CE，计算损失

- 预测任务：预测新的数值——回归方法

  - 用均方误差MSE方法，计算损失

    

### Part4-学习感想

- 学习了numpy的一些常用方法，感觉numpy在处理数组和矩阵方面非常方便。通过课堂练习，提高了编写简单函数的能力

- 深度学习中常用的激活函数并没有想象中的那么高深，基于常用的数学函数，进行布尔运算，构建逻辑门

- 对多层神经网络有了一点点理解，在理论学习之外，后面的课程会有实际操作，还需要在练习中加深理解

