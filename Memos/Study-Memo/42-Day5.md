# Week 5课程小结

## 学习内容

### 张量（Tensor）

+ 张量的实质---有统一类型(dtype)的 N维数组（且张量不可改变）
+ 张量表示神经网络的运算
+ 张量的创建
    + 利用tf.constant([[],[],...])创建
    + 张量的形状shape （每个维度的元素数量）
        + 简单判断：看开头或结尾处有几个括号
+ 张量运算
    + tf.matmul(a,b) -----a@b(矩阵乘积)
    + 张量广播：形状不同的张量做运算-->将张量拓展为同形状后再运算
+ 索引
    + 负索引----倒序（-1表示最后一个，因为没有-0）
    + 冒号：----切片，[a:b：c]----步长为c，范围为[a,b)
### 变量

+ 变量的创建（通过赋予初始值来给定形状）
    + 用tf.Variable()
    + 数据类型不限
+ 变量的值可以改变，但不能改变形状和数据类型，可用**tf**.reshape生成新张量
    + tf.reshape(变量名，(目标形状))----创建为一个新的张量
+ 变量值的改变用assign
    + a.assign_add/sub([1,2]) ---将a 的值改为原a+/-[1,2] 

### 自动微分

+ TensorFlow 为自动微分提供了 tf.GradientTape API ，根据某个函数的输 入变量来计算它的导数。

+ 默认情况下，调用 GradientTape.gradient() 方法时，GradientTape 占 用的资源会立即得到释放。 但通过创建一个持久的梯度带，可以计算同个函数的多个导数。
  + **with** tf.GradientTape(**persistent=True**) as t:

## 学习心得

+ 张量和变量的概念不难理解， 但相关操作涉及到的公式还是挺多的，需要多练习

+ 自动微分部分还有一些不太理解

  