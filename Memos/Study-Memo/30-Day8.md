# Day8

李高远 No.30

#### 模型的保存和加载

###### 保存和加载完整模型

- ```python
  tf.keras.models.load_model()
  ```

- ```python
  tf.keras.models.save_model() 
  model.save()
  ```

###### 仅保存架构

- ```python
  model.get_config()
  tf.keras.models.model_to_json()
  ```

- ```python
  model.from_config()
  tf.keras.models.model_from_json()
  ```

###### 保存权重(在内存中使用)

- ```python
  model.get_weights()
  ```

- ```python
  model.set_weights()
  ```

#### 卷积网络

###### 卷积核

- 卷积核：多维数组，由学习算法得到
- 卷积：对输入的数组运行卷积运算

###### 有填充式

- 在周围填上一圈以进行计算
- Padding，Zero-padding

###### 下采样层 subsample / down sampling

- 缩小输出张量的大小
- Max-pooling 和 Avg-pooling

###### 归一化层 Normalization

- LCN 减去平均值，除以标准差  
- LCN的亮度不变性——用于图像识别

###### 卷积网络的层间连接

- 卷积核运算等效于局部规则连接 Locally Connected
- 区别于全连接网络Dense的全连接 Fully Connected

###### 卷积网络的发展

- LeNet-5 手写字体识别 

  Handwritten digit recognition with a back-propagation network NIPS 1989

- AlexNet 

  第二层分成上下两个张量：并行计算（多GPU）

  Max-Pooling 

  第二层的卷积核：5\*5*48

  最后三层 4096 dense

  相比LeNet<u>更深的层数、更多的参数、更强大的硬件（GPU）、更大的数据集、更好的正则化（dropouts）</u>

- 新发展

  ResNet 残差网络

  DenseNet 


###### 卷积网络的实际应用

- 图像识别 

  MNIST数据集

  MLP - 全连接dense层 单个神经元有200\*200\*3个参数

  卷积网络优点——参数少（参数市卷积核的大小乘以卷积核的个数）、并行化（不同卷积核独立运算）、运算快（直接硬件实现从而加速）

- 人脸辨识

  feature learning 特征学习 

  对象检测


#### Keras CNN

###### 卷积层

```python
tf.keras.layers.Conv2D()
```

###### 池化层 Pooling

```python
tf.keras.layers.MaxPool3D()
tf.keras.layers.AveragePooling3D()
```

###### 随即丢弃层 Dropouts

减少CNN过拟合的问题

超参数：keep_prob 丢弃率   有keep_prob 概率被保留，以保证前后总和大致相等，否则输出0

```python
tf.keras.layers.Dropouts()
```

###### 归一化层 Normalization

通过均值和标准差执行归一化

#### Keras - Dense 基本图像分类

###### Fashion MNIST 数据集

60,000 个图像训练网络，10,000 个图像评估网络

过拟合的模型会记住训练集中的噪声和细节  ——   在新的输入上表现较差